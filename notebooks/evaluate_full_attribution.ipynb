{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full Attribution Evaluation\n",
        "\n",
        "Evaluate all full attribution files and display results in a table format.\n",
        "Each file contains a judge model's predictions on which code belongs to which model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Paths\n",
        "BASE_DIR = Path(\"/Users/ehsan/CursorProjects/llm-collusion\")\n",
        "FULL_ATTRIBUTION_DIR = BASE_DIR / \"data\" / \"full_attribution\" / \"mbpp-sanitized\" / \"test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_attribution_labels(records):\n",
        "    \"\"\"Extract labels from full attribution records.\"\"\"\n",
        "    y_true, y_pred = [], []\n",
        "    \n",
        "    if not records:\n",
        "        return y_true, y_pred\n",
        "    \n",
        "    # Get model names\n",
        "    model1 = records[0].get(\"model1\")\n",
        "    model2 = records[0].get(\"model2\")\n",
        "    if not model1 or not model2:\n",
        "        return y_true, y_pred\n",
        "    \n",
        "    for r in records:\n",
        "        gold = r.get(\"gold_attribution\")\n",
        "        pred = r.get(\"predicted_attribution\")\n",
        "        if not gold or not pred:\n",
        "            continue\n",
        "        \n",
        "        # Code1\n",
        "        g1 = gold.get(\"Code1\")\n",
        "        p1 = pred.get(\"Code1\")\n",
        "        if g1 in (model1, model2) and p1 in (model1, model2):\n",
        "            y_true.append(0 if g1 == model1 else 1)\n",
        "            y_pred.append(0 if p1 == model1 else 1)\n",
        "        \n",
        "        # Code2\n",
        "        g2 = gold.get(\"Code2\")\n",
        "        p2 = pred.get(\"Code2\")\n",
        "        if g2 in (model1, model2) and p2 in (model1, model2):\n",
        "            y_true.append(0 if g2 == model1 else 1)\n",
        "            y_pred.append(0 if p2 == model1 else 1)\n",
        "    \n",
        "    return y_true, y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 files to evaluate\n",
            "\n",
            "====================================================================================================\n",
            "FULL ATTRIBUTION EVALUATION RESULTS\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Judge Model</th>\n",
              "      <th>Model 1</th>\n",
              "      <th>Model 2</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy %</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Code Items</th>\n",
              "      <th>Records</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Correct %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>judge-x-ai-grok-code-fast-1_classify-anthropic...</td>\n",
              "      <td>x-ai/grok-code-fast-1</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>80.47%</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>512</td>\n",
              "      <td>257</td>\n",
              "      <td>206</td>\n",
              "      <td>80.16%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>judge-anthropic-claude-sonnet-4.5_classify-ant...</td>\n",
              "      <td>anthropic/claude-sonnet-4.5</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>0.774319</td>\n",
              "      <td>77.43%</td>\n",
              "      <td>0.774319</td>\n",
              "      <td>0.774319</td>\n",
              "      <td>0.774319</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "      <td>199</td>\n",
              "      <td>77.43%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>judge-x-ai-grok-4.1-fast_classify-anthropic-cl...</td>\n",
              "      <td>x-ai/grok-4.1-fast</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>0.747082</td>\n",
              "      <td>74.71%</td>\n",
              "      <td>0.747082</td>\n",
              "      <td>0.747082</td>\n",
              "      <td>0.747082</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "      <td>192</td>\n",
              "      <td>74.71%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>judge-openai-gpt-5.1-codex_classify-anthropic-...</td>\n",
              "      <td>openai/gpt-5.1-codex</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>0.692607</td>\n",
              "      <td>69.26%</td>\n",
              "      <td>0.692607</td>\n",
              "      <td>0.692607</td>\n",
              "      <td>0.692607</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "      <td>178</td>\n",
              "      <td>69.26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>judge-openai-gpt-5_classify-openai-gpt-5_vs_an...</td>\n",
              "      <td>openai/gpt-5</td>\n",
              "      <td>gpt-5</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>66.67%</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>510</td>\n",
              "      <td>257</td>\n",
              "      <td>170</td>\n",
              "      <td>66.15%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>judge-openai-gpt-5_classify-anthropic-claude-h...</td>\n",
              "      <td>openai/gpt-5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>65.23%</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>512</td>\n",
              "      <td>257</td>\n",
              "      <td>167</td>\n",
              "      <td>64.98%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>judge-openai-gpt-5_classify-deepseek-deepseek-...</td>\n",
              "      <td>openai/gpt-5</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>0.644269</td>\n",
              "      <td>64.43%</td>\n",
              "      <td>0.644269</td>\n",
              "      <td>0.644269</td>\n",
              "      <td>0.644269</td>\n",
              "      <td>506</td>\n",
              "      <td>257</td>\n",
              "      <td>163</td>\n",
              "      <td>63.42%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>judge-google-gemini-3-pro-preview_classify-ant...</td>\n",
              "      <td>google/gemini-3-pro-preview</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>63.64%</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>110</td>\n",
              "      <td>76</td>\n",
              "      <td>35</td>\n",
              "      <td>46.05%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>judge-qwen-qwen3-coder-30b-a3b-instruct_classi...</td>\n",
              "      <td>qwen/qwen3-coder-30b-a3b-instruct</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>0.585938</td>\n",
              "      <td>58.59%</td>\n",
              "      <td>0.585946</td>\n",
              "      <td>0.585946</td>\n",
              "      <td>0.585938</td>\n",
              "      <td>512</td>\n",
              "      <td>257</td>\n",
              "      <td>150</td>\n",
              "      <td>58.37%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>judge-google-gemini-2.5-flash_classify-anthrop...</td>\n",
              "      <td>google/gemini-2.5-flash</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>51.36%</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "      <td>132</td>\n",
              "      <td>51.36%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                File  \\\n",
              "0  judge-x-ai-grok-code-fast-1_classify-anthropic...   \n",
              "1  judge-anthropic-claude-sonnet-4.5_classify-ant...   \n",
              "2  judge-x-ai-grok-4.1-fast_classify-anthropic-cl...   \n",
              "3  judge-openai-gpt-5.1-codex_classify-anthropic-...   \n",
              "4  judge-openai-gpt-5_classify-openai-gpt-5_vs_an...   \n",
              "5  judge-openai-gpt-5_classify-anthropic-claude-h...   \n",
              "6  judge-openai-gpt-5_classify-deepseek-deepseek-...   \n",
              "7  judge-google-gemini-3-pro-preview_classify-ant...   \n",
              "8  judge-qwen-qwen3-coder-30b-a3b-instruct_classi...   \n",
              "9  judge-google-gemini-2.5-flash_classify-anthrop...   \n",
              "\n",
              "                         Judge Model                Model 1  \\\n",
              "0              x-ai/grok-code-fast-1  deepseek-chat-v3-0324   \n",
              "1        anthropic/claude-sonnet-4.5       claude-haiku-4.5   \n",
              "2                 x-ai/grok-4.1-fast       claude-haiku-4.5   \n",
              "3               openai/gpt-5.1-codex       claude-haiku-4.5   \n",
              "4                       openai/gpt-5                  gpt-5   \n",
              "5                       openai/gpt-5  deepseek-chat-v3-0324   \n",
              "6                       openai/gpt-5       claude-haiku-4.5   \n",
              "7        google/gemini-3-pro-preview       claude-haiku-4.5   \n",
              "8  qwen/qwen3-coder-30b-a3b-instruct  deepseek-chat-v3-0324   \n",
              "9            google/gemini-2.5-flash       claude-haiku-4.5   \n",
              "\n",
              "                 Model 2  Accuracy Accuracy %  Precision    Recall  F1-Score  \\\n",
              "0       claude-haiku-4.5  0.804688     80.47%   0.804688  0.804688  0.804688   \n",
              "1  deepseek-chat-v3-0324  0.774319     77.43%   0.774319  0.774319  0.774319   \n",
              "2  deepseek-chat-v3-0324  0.747082     74.71%   0.747082  0.747082  0.747082   \n",
              "3  deepseek-chat-v3-0324  0.692607     69.26%   0.692607  0.692607  0.692607   \n",
              "4       claude-haiku-4.5  0.666667     66.67%   0.666667  0.666667  0.666667   \n",
              "5       claude-haiku-4.5  0.652344     65.23%   0.652344  0.652344  0.652344   \n",
              "6  deepseek-chat-v3-0324  0.644269     64.43%   0.644269  0.644269  0.644269   \n",
              "7  deepseek-chat-v3-0324  0.636364     63.64%   0.636364  0.636364  0.636364   \n",
              "8       claude-haiku-4.5  0.585938     58.59%   0.585946  0.585946  0.585938   \n",
              "9  deepseek-chat-v3-0324  0.513619     51.36%   0.513619  0.513619  0.513619   \n",
              "\n",
              "   Code Items  Records  Correct Correct %  \n",
              "0         512      257      206    80.16%  \n",
              "1         514      257      199    77.43%  \n",
              "2         514      257      192    74.71%  \n",
              "3         514      257      178    69.26%  \n",
              "4         510      257      170    66.15%  \n",
              "5         512      257      167    64.98%  \n",
              "6         506      257      163    63.42%  \n",
              "7         110       76       35    46.05%  \n",
              "8         512      257      150    58.37%  \n",
              "9         514      257      132    51.36%  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all full attribution files\n",
        "all_files = sorted(list(FULL_ATTRIBUTION_DIR.glob(\"*.jsonl\")))\n",
        "print(f\"Found {len(all_files)} files to evaluate\\n\")\n",
        "\n",
        "# Evaluate each file\n",
        "results = []\n",
        "\n",
        "for file_path in all_files:\n",
        "    # Load records\n",
        "    records = [json.loads(line) for line in open(file_path) if line.strip()]\n",
        "    \n",
        "    if not records:\n",
        "        continue\n",
        "    \n",
        "    # Extract metadata\n",
        "    judge_model = records[0].get(\"judge_model\", \"unknown\")\n",
        "    model1 = records[0].get(\"model1\", \"unknown\")\n",
        "    model2 = records[0].get(\"model2\", \"unknown\")\n",
        "    \n",
        "    # Extract labels and compute metrics\n",
        "    y_true, y_pred = extract_attribution_labels(records)\n",
        "    \n",
        "    if len(y_true) == 0:\n",
        "        continue\n",
        "    \n",
        "    # Compute metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
        "    \n",
        "    # Count correct predictions\n",
        "    correct_count = sum(1 for r in records if r.get(\"is_correct\", False))\n",
        "    total_records = len(records)\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"File\": file_path.name,\n",
        "        \"Judge Model\": judge_model,\n",
        "        \"Model 1\": model1.split(\"/\")[-1] if \"/\" in model1 else model1,\n",
        "        \"Model 2\": model2.split(\"/\")[-1] if \"/\" in model2 else model2,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Accuracy %\": f\"{acc*100:.2f}%\",\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1,\n",
        "        \"Code Items\": len(y_true),\n",
        "        \"Records\": total_records,\n",
        "        \"Correct\": correct_count,\n",
        "        \"Correct %\": f\"{correct_count/total_records*100:.2f}%\" if total_records > 0 else \"0%\"\n",
        "    })\n",
        "\n",
        "# Create DataFrame and sort by accuracy (descending)\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display results table\n",
        "print(\"=\" * 100)\n",
        "print(\"FULL ATTRIBUTION EVALUATION RESULTS\")\n",
        "print(\"=\" * 100)\n",
        "print()\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "SUMMARY STATISTICS\n",
            "====================================================================================================\n",
            "\n",
            "Total files evaluated: 10\n",
            "\n",
            "Accuracy Statistics:\n",
            "  Mean:   0.6718 (67.18%)\n",
            "  Median: 0.6595 (65.95%)\n",
            "  Min:    0.5136 (51.36%)\n",
            "  Max:    0.8047 (80.47%)\n",
            "\n",
            "F1-Score Statistics:\n",
            "  Mean:   0.6718\n",
            "  Median: 0.6595\n",
            "  Min:    0.5136\n",
            "  Max:    0.8047\n",
            "\n",
            "Total code items evaluated: 4,718\n",
            "Total records: 2,389\n"
          ]
        }
      ],
      "source": [
        "# Summary statistics\n",
        "if len(df_results) > 0:\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"\\nTotal files evaluated: {len(df_results)}\")\n",
        "    print(f\"\\nAccuracy Statistics:\")\n",
        "    print(f\"  Mean:   {df_results['Accuracy'].mean():.4f} ({df_results['Accuracy'].mean()*100:.2f}%)\")\n",
        "    print(f\"  Median: {df_results['Accuracy'].median():.4f} ({df_results['Accuracy'].median()*100:.2f}%)\")\n",
        "    print(f\"  Min:    {df_results['Accuracy'].min():.4f} ({df_results['Accuracy'].min()*100:.2f}%)\")\n",
        "    print(f\"  Max:    {df_results['Accuracy'].max():.4f} ({df_results['Accuracy'].max()*100:.2f}%)\")\n",
        "    print(f\"\\nF1-Score Statistics:\")\n",
        "    print(f\"  Mean:   {df_results['F1-Score'].mean():.4f}\")\n",
        "    print(f\"  Median: {df_results['F1-Score'].median():.4f}\")\n",
        "    print(f\"  Min:    {df_results['F1-Score'].min():.4f}\")\n",
        "    print(f\"  Max:    {df_results['F1-Score'].max():.4f}\")\n",
        "    print(f\"\\nTotal code items evaluated: {df_results['Code Items'].sum():,}\")\n",
        "    print(f\"Total records: {df_results['Records'].sum():,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "RESULTS SORTED BY ACCURACY (HIGHEST TO LOWEST)\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Judge Model</th>\n",
              "      <th>Model 1</th>\n",
              "      <th>Model 2</th>\n",
              "      <th>Accuracy %</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Code Items</th>\n",
              "      <th>Records</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>judge-x-ai-grok-code-fast-1_classify-anthropic...</td>\n",
              "      <td>x-ai/grok-code-fast-1</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>80.47%</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>512</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>judge-anthropic-claude-sonnet-4.5_classify-ant...</td>\n",
              "      <td>anthropic/claude-sonnet-4.5</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>77.43%</td>\n",
              "      <td>0.774319</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>judge-x-ai-grok-4.1-fast_classify-anthropic-cl...</td>\n",
              "      <td>x-ai/grok-4.1-fast</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>74.71%</td>\n",
              "      <td>0.747082</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>judge-openai-gpt-5.1-codex_classify-anthropic-...</td>\n",
              "      <td>openai/gpt-5.1-codex</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>69.26%</td>\n",
              "      <td>0.692607</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>judge-openai-gpt-5_classify-openai-gpt-5_vs_an...</td>\n",
              "      <td>openai/gpt-5</td>\n",
              "      <td>gpt-5</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>66.67%</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>510</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>judge-openai-gpt-5_classify-anthropic-claude-h...</td>\n",
              "      <td>openai/gpt-5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>65.23%</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>512</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>judge-openai-gpt-5_classify-deepseek-deepseek-...</td>\n",
              "      <td>openai/gpt-5</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>64.43%</td>\n",
              "      <td>0.644269</td>\n",
              "      <td>506</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>judge-google-gemini-3-pro-preview_classify-ant...</td>\n",
              "      <td>google/gemini-3-pro-preview</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>63.64%</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>110</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>judge-qwen-qwen3-coder-30b-a3b-instruct_classi...</td>\n",
              "      <td>qwen/qwen3-coder-30b-a3b-instruct</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>58.59%</td>\n",
              "      <td>0.585938</td>\n",
              "      <td>512</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>judge-google-gemini-2.5-flash_classify-anthrop...</td>\n",
              "      <td>google/gemini-2.5-flash</td>\n",
              "      <td>claude-haiku-4.5</td>\n",
              "      <td>deepseek-chat-v3-0324</td>\n",
              "      <td>51.36%</td>\n",
              "      <td>0.513619</td>\n",
              "      <td>514</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                File  \\\n",
              "0  judge-x-ai-grok-code-fast-1_classify-anthropic...   \n",
              "1  judge-anthropic-claude-sonnet-4.5_classify-ant...   \n",
              "2  judge-x-ai-grok-4.1-fast_classify-anthropic-cl...   \n",
              "3  judge-openai-gpt-5.1-codex_classify-anthropic-...   \n",
              "4  judge-openai-gpt-5_classify-openai-gpt-5_vs_an...   \n",
              "5  judge-openai-gpt-5_classify-anthropic-claude-h...   \n",
              "6  judge-openai-gpt-5_classify-deepseek-deepseek-...   \n",
              "7  judge-google-gemini-3-pro-preview_classify-ant...   \n",
              "8  judge-qwen-qwen3-coder-30b-a3b-instruct_classi...   \n",
              "9  judge-google-gemini-2.5-flash_classify-anthrop...   \n",
              "\n",
              "                         Judge Model                Model 1  \\\n",
              "0              x-ai/grok-code-fast-1  deepseek-chat-v3-0324   \n",
              "1        anthropic/claude-sonnet-4.5       claude-haiku-4.5   \n",
              "2                 x-ai/grok-4.1-fast       claude-haiku-4.5   \n",
              "3               openai/gpt-5.1-codex       claude-haiku-4.5   \n",
              "4                       openai/gpt-5                  gpt-5   \n",
              "5                       openai/gpt-5  deepseek-chat-v3-0324   \n",
              "6                       openai/gpt-5       claude-haiku-4.5   \n",
              "7        google/gemini-3-pro-preview       claude-haiku-4.5   \n",
              "8  qwen/qwen3-coder-30b-a3b-instruct  deepseek-chat-v3-0324   \n",
              "9            google/gemini-2.5-flash       claude-haiku-4.5   \n",
              "\n",
              "                 Model 2 Accuracy %  F1-Score  Code Items  Records  \n",
              "0       claude-haiku-4.5     80.47%  0.804688         512      257  \n",
              "1  deepseek-chat-v3-0324     77.43%  0.774319         514      257  \n",
              "2  deepseek-chat-v3-0324     74.71%  0.747082         514      257  \n",
              "3  deepseek-chat-v3-0324     69.26%  0.692607         514      257  \n",
              "4       claude-haiku-4.5     66.67%  0.666667         510      257  \n",
              "5       claude-haiku-4.5     65.23%  0.652344         512      257  \n",
              "6  deepseek-chat-v3-0324     64.43%  0.644269         506      257  \n",
              "7  deepseek-chat-v3-0324     63.64%  0.636364         110       76  \n",
              "8       claude-haiku-4.5     58.59%  0.585938         512      257  \n",
              "9  deepseek-chat-v3-0324     51.36%  0.513619         514      257  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sort by accuracy (descending) for easier comparison\n",
        "df_results_sorted = df_results.sort_values('Accuracy', ascending=False)\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"RESULTS SORTED BY ACCURACY (HIGHEST TO LOWEST)\")\n",
        "print(\"=\" * 100)\n",
        "print()\n",
        "df_results_sorted[['File', 'Judge Model', 'Model 1', 'Model 2', 'Accuracy %', 'F1-Score', 'Code Items', 'Records']]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
