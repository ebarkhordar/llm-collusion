{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross-Model Detection Analysis\n",
        "\n",
        "This notebook analyzes the ability of GPT-5 to identify code written by other LLM families (e.g., Claude).\n",
        "\n",
        "## Key Finding\n",
        "\n",
        "**GPT-5 is better at identifying Claude's code than its own code!**\n",
        "\n",
        "### Results Summary\n",
        "\n",
        "| Task | Accuracy | Details |\n",
        "|------|----------|----------|\n",
        "| GPT-5 self-recognition | 79.2% | GPT-5 identifying its own code (202/255 correct) |\n",
        "| GPT-5 detecting Claude | **97.7%** | GPT-5 identifying Claude's code (251/257 correct) |\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "This surprising result suggests:\n",
        "1. Claude has very distinctive coding patterns that are easier for GPT-5 to identify\n",
        "2. Different model families may have more distinguishable \"signatures\" than models recognizing their own output\n",
        "3. This could strengthen the paper's motivation: stronger models like GPT-5 can act as \"monitors\" to detect code from other LLM families\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_results(file_path):\n",
        "    \"\"\"Load results from JSONL file.\"\"\"\n",
        "    results = []\n",
        "    with open(file_path) as f:\n",
        "        for line in f:\n",
        "            results.append(json.loads(line))\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Load self-recognition results\n",
        "self_recognition_path = Path(\"../data/self_recognition/mbpp-sanitized/test/openai-gpt-5.jsonl\")\n",
        "self_rec_df = load_results(self_recognition_path)\n",
        "\n",
        "# Load cross-model detection results\n",
        "cross_detection_path = Path(\"../data/cross_model_detection/mbpp-sanitized/test/judge-openai-gpt-5_target-anthropic-claude-haiku-4.5.jsonl\")\n",
        "cross_det_df = load_results(cross_detection_path)\n",
        "\n",
        "print(f\"Self-recognition samples: {len(self_rec_df)}\")\n",
        "print(f\"Cross-detection samples: {len(cross_det_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Self-recognition accuracy\n",
        "self_rec_valid = self_rec_df[self_rec_df['is_correct'].notna()]\n",
        "self_rec_acc = self_rec_valid['is_correct'].mean()\n",
        "self_rec_correct = self_rec_valid['is_correct'].sum()\n",
        "self_rec_total = len(self_rec_valid)\n",
        "\n",
        "print(f\"Self-Recognition (GPT-5 identifying own code):\")\n",
        "print(f\"  Accuracy: {self_rec_acc:.3f} ({self_rec_correct}/{self_rec_total})\")\n",
        "\n",
        "# Cross-detection accuracy\n",
        "cross_det_valid = cross_det_df[cross_det_df['is_correct'].notna()]\n",
        "cross_det_acc = cross_det_valid['is_correct'].mean()\n",
        "cross_det_correct = cross_det_valid['is_correct'].sum()\n",
        "cross_det_total = len(cross_det_valid)\n",
        "\n",
        "print(f\"\\nCross-Model Detection (GPT-5 identifying Claude's code):\")\n",
        "print(f\"  Accuracy: {cross_det_acc:.3f} ({cross_det_correct}/{cross_det_total})\")\n",
        "\n",
        "print(f\"\\nImprovement: +{(cross_det_acc - self_rec_acc) * 100:.1f} percentage points\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison bar plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "tasks = ['Self-Recognition\\n(GPT-5 own code)', 'Cross-Detection\\n(GPT-5 â†’ Claude)']\n",
        "accuracies = [self_rec_acc, cross_det_acc]\n",
        "colors = ['#3498db', '#e74c3c']\n",
        "\n",
        "bars = ax.bar(tasks, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "            f'{acc:.1%}',\n",
        "            ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax.set_ylim(0, 1.1)\n",
        "ax.set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
        "ax.set_title('GPT-5 Performance: Self-Recognition vs Cross-Model Detection', \n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random chance')\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../data/cross_model_detection/comparison_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Plot saved to: data/cross_model_detection/comparison_plot.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implications for the Paper\n",
        "\n",
        "### New Motivation\n",
        "\n",
        "The paper can now argue that:\n",
        "1. **Stronger models like GPT-5 can act as effective monitors** for detecting code from other LLM families\n",
        "2. **Cross-model detection may be easier than self-recognition** - suggesting that different model families have more distinguishable signatures\n",
        "3. **This has implications for AI safety and monitoring** - one model family can potentially monitor outputs from another\n",
        "\n",
        "### Potential Follow-up Experiments\n",
        "\n",
        "1. Test other judge-target combinations (e.g., Claude detecting GPT-5)\n",
        "2. Test detection across more model families (Gemini, DeepSeek, Grok)\n",
        "3. Analyze what features make Claude's code so identifiable\n",
        "4. Test whether fine-tuning can make models better at cross-model detection\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
